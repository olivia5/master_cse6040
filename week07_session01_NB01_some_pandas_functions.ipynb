{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olivia5/master_cse6040/blob/main/week07_session01_NB01_some_pandas_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxT-4Efmoeh0"
      },
      "source": [
        "_Main topics covered during today's session:_\n",
        "\n",
        "This NB:\n",
        "\n",
        "1. **Pandas Functions:**\n",
        "    \n",
        "    a. Index operations\n",
        "    \n",
        "    b. Concat\n",
        "    \n",
        "    c. Merge\n",
        "    \n",
        "    d. Groupby and Aggregation\n",
        "    \n",
        "Next NB:\n",
        "\n",
        "2. **Troubleshooting pandas dataframes**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snP6N-Lloeh2"
      },
      "source": [
        "**The below three cells simply set up the NB with the same two df's as the NB's from the previous session (cafes#).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Cfc-dSSoeh3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd  # Standard idiom for loading pandas\n",
        "from pandas import DataFrame, Series\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTu7dFd-oeh3"
      },
      "outputs": [],
      "source": [
        "cafes = DataFrame({'name': ['east pole', 'chrome yellow', 'brash', 'taproom', '3heart', 'spiller park pcm', 'refuge', 'toptime'],\n",
        "                   'zip': [30324, 30312, 30318, 30317, 30306, 30308, 30303, 30318],\n",
        "                   'poc': ['jared', 'kelly', 'matt', 'jonathan', 'nhan', 'dale', 'kitti', 'nolan']})\n",
        "\n",
        "cafes2 = cafes[['poc', 'zip']]\n",
        "cafes2.index = cafes['name']\n",
        "cafes2.index.name = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UenA9TDRoeh4"
      },
      "outputs": [],
      "source": [
        "cafes2['rating'] = 4.0\n",
        "cafes2['price'] = '$$'\n",
        "prices_as_ints = cafes2['price'].apply(lambda s: len(s))\n",
        "cafes2['value'] = cafes2['rating'] / prices_as_ints\n",
        "cafes3 = cafes2.copy()\n",
        "is_fancy = cafes3['zip'].isin({30306, 30308})\n",
        "cafes3.loc[is_fancy, 'price'] += '$'\n",
        "cafes4 = cafes3.copy()\n",
        "def calc_value(row):\n",
        "    return row['rating'] / len(row['price'])\n",
        "\n",
        "cafes4['value'] = cafes4.apply(calc_value, axis=1)\n",
        "cafes4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiD44P9moeh4"
      },
      "source": [
        "## Index objects\n",
        "\n",
        "A pandas [`Index`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Index.html), used by `Series` and `DataFrame`, is \"list-like.\" It has a number of useful operations, including set-like operations (e.g., testing for membership, intersection, union, difference):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlNS_n0moeh4"
      },
      "outputs": [],
      "source": [
        "from pandas import Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QD7b925oeh5"
      },
      "outputs": [],
      "source": [
        "# what are the index names?\n",
        "cafes4.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ES03MUQoeh5"
      },
      "outputs": [],
      "source": [
        "# boolean mask/membership\n",
        "cafes4.index.isin(['brash', '3heart'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8QDE0ngoeh5"
      },
      "source": [
        "#### The next few cells show index operations, to illustrate some things that you can do with indexes. We include them only to maintain compatibility with the NB on Vocareum, but we skip over them in our discussion, proceeding directly to reindexing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsLqRClmoeh5"
      },
      "outputs": [],
      "source": [
        "# create an union with a new value\n",
        "cafes4.index.union(['chattahoochee'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjNg2lMNoeh5"
      },
      "outputs": [],
      "source": [
        "# return the difference\n",
        "cafes4.index.difference(['chattahoochee', 'starbucks', 'bar crema'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSEt1JT-oeh6"
      },
      "source": [
        "If you need to change the index of a `DataFrame`, here is one way to do it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98Hpk_2toeh6"
      },
      "outputs": [],
      "source": [
        "cafes5 = cafes4.reindex(Index(['3heart', 'east pole', 'brash', 'starbucks']))\n",
        "\n",
        "display(cafes4)\n",
        "display(cafes5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGk7OWGboeh6"
      },
      "source": [
        "Observe that this reindexing operation matches the supplied index values against the existing ones. (What happens to index values you leave out? What happens with new index values?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiI0w30qoeh6"
      },
      "source": [
        "**Below is an index operation that is useful. You will see this in future NB's and can expect to be asked to apply this funcationality in testing scenarios (MT2 and Final exam).**\n",
        "\n",
        "**As an aside, you can expect to be required to show your proficiency with everything in this NB on the exams.**\n",
        "\n",
        "Another useful operation is dropping the index (and replacing it with the default, integers)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNBo4Ndnoeh6"
      },
      "outputs": [],
      "source": [
        "# print for initial reference\n",
        "cafes4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3G9NWVd2oeh6"
      },
      "outputs": [],
      "source": [
        "# create a new df, cafes6, and\n",
        "# reset the index from the string names to integers\n",
        "cafes6 = cafes4.reset_index(drop=True)\n",
        "cafes6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_q16VlToeh6"
      },
      "source": [
        "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reset_index.html\n",
        "\n",
        "From the documentation:  Reset the index of the DataFrame, and use the default one instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RiQ3z14oeh6"
      },
      "outputs": [],
      "source": [
        "# create a new column from the index of the other df\n",
        "# recall that the other index is strings\n",
        "cafes6['name'] = cafes4.index\n",
        "cafes6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHiouidaoeh6"
      },
      "source": [
        "### Now let's look at the concat() function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7McXwVKoeh7"
      },
      "source": [
        "Another useful operation is gluing `DataFrame` objects together. There are several helpful operations covered in Notebook 7; one not mentioned there, but useful in one of its exercises, is `.concat()`.\n",
        "\n",
        "The below material is partially adapted from \"The Python Data Science Handbook\" by Jake VanderPlas, Chapter 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rI_vxjA4oeh7"
      },
      "source": [
        "Here is the documentation page for .concat():\n",
        "\n",
        "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html\n",
        "\n",
        "Note that the only arguments required are the objects to be concatenated.\n",
        "\n",
        "1. The default axis=0, which means the concatenation is done along the indexes (rows). From a practical perspective, what this means is that the second listed df (or 3rd, 4th, etc) is \"attached\" to the bottom of the 1st listed dataframe.\n",
        "\n",
        "2. The default join is 'outer' join, which means to bring all rows in. We will cover joins in detail during our SQL module, but in this case, the outer join means to bring in all rows from both dataframes.\n",
        "\n",
        "3. Pandas concatenation preserves indexes, even if the result will have duplicate indexes. The verify_integrity option handles duplicates, and please see the documentation for specifics. You will generally not need to worry about this option during the class.\n",
        "\n",
        "So let's look at an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4i2PBjmoeh7"
      },
      "outputs": [],
      "source": [
        "# Split based on price\n",
        "# create a boolean mask\n",
        "is_cheap = cafes4['price'] <= '$$'\n",
        "\n",
        "# create 2 df's, based on the mask\n",
        "cafes_cheap = cafes4[is_cheap]   #cheap\n",
        "cafes_pricey = cafes4[~is_cheap]  #not cheap\n",
        "\n",
        "display(cafes_cheap)\n",
        "display(cafes_pricey)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJTSm0tZoeh7"
      },
      "outputs": [],
      "source": [
        "# Never mind; recombine\n",
        "pd.concat([cafes_cheap, cafes_pricey])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSLHKug8oeh7"
      },
      "source": [
        "The .concate() function will bring together dataframes with the same column names and will also join those with different column names. In general, we will not exercise the latter case in this class, but there are numerous examples available online which show how pandas does this. A very good reference with examples is VanderPlas:\n",
        "\n",
        "https://jakevdp.github.io/PythonDataScienceHandbook/03.06-concat-and-append.html\n",
        "\n",
        "https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.06-Concat-And-Append.ipynb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yv5YyQBXoeh7"
      },
      "source": [
        "### Next is the merge() function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dM62Kfboeh7"
      },
      "source": [
        "One essential feature offered by Pandas is its high-performance, in-memory join and merge operations.\n",
        "If you have ever worked with databases, you should be familiar with this type of data interaction.\n",
        "\n",
        "In SQL, this is a select and join of two tables.\n",
        "\n",
        "The main interface for this is the ``pd.merge`` function, which you will use extensively in this class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4t8Dz5mBoeh7"
      },
      "source": [
        "Here is the documentation page for .merge():\n",
        "\n",
        "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.merge.html\n",
        "\n",
        "The first 6 parameters are important for us to know about, and to know how to use. You may use the remaining parameters, but these first 6 are absolutely necessary for you to understand and use.\n",
        "\n",
        "**pandas.merge(left, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=True, indicator=False, validate=None)**\n",
        "\n",
        "\n",
        "1. The 'left' and 'right' parameters define the two dataframes to merge on. It is important for you to designate and remember which df is left and which is right, as 3 of the 4 remaining parameters use them.\n",
        "\n",
        "2. The 'how' parameter designates the type of join operation to perform (left, right, outer, inner, cross). We will cover these in detail during our SQL module next week.\n",
        "\n",
        "3. The 'on' parameter gives the column(s) or index level names to join on. Whatever you designate for this parameter must be contained in both the left and right df's.\n",
        "\n",
        "4. You can use the 'left_on' and 'right_on' parameters when the two dataframes do not have identically-named columns, but they have differently-named columns that have the same values, and you can join on them. We will show an example of this below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD3dwEGgoeh7"
      },
      "source": [
        "**Specifying the merge key:**\n",
        "\n",
        "The default behavior of pd.merge() is that it looks for one or more matching column names between the two inputs, and uses this as the key. Note that the default value for the 'on' parameter is None, so if you do not specify the column names to merge on, the function will attempt to execute its default behavior.\n",
        "\n",
        "However, often the column names will not match so nicely, and pd.merge() provides a variety of options for handling this.\n",
        "\n",
        "You have several options for specifying how to merge:\n",
        "\n",
        "1. You can explicitly specify the name of the key column using the on keyword, which takes a column name or a list of column names. Note that this only works if both the left and right dataframes have the specified column name.\n",
        "\n",
        "2. The left_on and right_on keywords are useful when you want to merge two datasets with different column names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUhV1wC5oeh7"
      },
      "outputs": [],
      "source": [
        "df1 = pd.DataFrame({'employee': ['Bob', 'Jake', 'Lisa', 'Sue','Chris','Rich'],\n",
        "                    'group': ['Accounting', 'Engineering', 'Engineering', 'HR','IT','Engineering']})\n",
        "df2 = pd.DataFrame({'employee': ['Lisa', 'Bob', 'Jake', 'Sue'],\n",
        "                    'hire_date': [2004, 2008, 2012, 2014]})\n",
        "df3 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
        "                    'salary': [70000, 80000, 120000, 90000]})\n",
        "display(df1, df2,df3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HFKPD2Roeh7"
      },
      "outputs": [],
      "source": [
        "# option 1 above, using on\n",
        "display(df1, df2, pd.merge(df1, df2, on='employee'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quyaLKH_oeh7"
      },
      "outputs": [],
      "source": [
        "# option 2 above, using left_on and right_on\n",
        "# note the designation of the left and right df's, and then using the correct *_on column names\n",
        "display(df1, df3, pd.merge(df1, df3, left_on=\"employee\", right_on=\"name\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evzfsuytoeh8"
      },
      "source": [
        "**The default value for the 'how' parameter is inner. As the documentation states:  inner: use intersection of keys from both frames, similar to a SQL inner join; preserve the order of the left keys.**\n",
        "\n",
        "In layman's terms, what this means is that the only keys returned will be those that are in both the left and right df's.\n",
        "\n",
        "Review againg the first join between df1 and df2. The key values from df2 of 'Rich' and 'Chris' are not in df1, so they are not included in the inner join.\n",
        "\n",
        "So let's set the join to outer and see what happens.**Again, from the documentation:  outer: use union of keys from both frames, similar to a SQL full outer join; sort keys lexicographically.**\n",
        "\n",
        "Additionally, the outer join fills in all missing values with NAs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFx79RqZoeh8"
      },
      "outputs": [],
      "source": [
        "# option 1 above, using on, this time as an outer join\n",
        "display(df1, df2, pd.merge(df1, df2, on='employee', how='outer'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kv34xyFjoeh8"
      },
      "source": [
        "See the 'hire_date' values for Chris and Rich, they are NaN values, as specified.\n",
        "\n",
        "We will spend more time on the join types in SQL next week, and know that all of the behaviors you will learn about then will apply here. We simply want to introduce you to the function here.\n",
        "\n",
        "As noted above, the VanderPlas book has excellent coverage of this topic:\n",
        "\n",
        "https://jakevdp.github.io/PythonDataScienceHandbook/03.07-merge-and-join.html\n",
        "\n",
        "https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.07-Merge-and-Join.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPVF8WfSoeh8"
      },
      "source": [
        "### Finally, a short introduction to aggregation and the groupby function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1XlKiJnoeh8"
      },
      "source": [
        "Pandas supports the normal aggregate functions, such as min, max, mean, median, sum, etc.\n",
        "\n",
        "By default, aggregation and aggregate functions operate on the columns of the dataframe, or on the series.\n",
        "\n",
        "See the below examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5qB0R91oeh8"
      },
      "outputs": [],
      "source": [
        "# for a series\n",
        "rng = np.random.RandomState(42)  # set a random starting point\n",
        "agg_series = pd.Series(rng.rand(5))\n",
        "display(agg_series)\n",
        "display(agg_series.sum())\n",
        "display(agg_series.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASvUyUQzoeh8"
      },
      "outputs": [],
      "source": [
        "# for a dataframe\n",
        "df = pd.DataFrame({'A': rng.rand(5),\n",
        "                   'B': rng.rand(5)})\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52ZbnLlCoeh8"
      },
      "outputs": [],
      "source": [
        "df.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zur6pS6Yoeh8"
      },
      "source": [
        "By specifying the axis argument, you can instead aggregate within each row:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIStVWaToeh8"
      },
      "outputs": [],
      "source": [
        "df.mean(axis='columns')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k36cB9T5oeh8"
      },
      "source": [
        "Finally, there is a convenience method, describe(), that computes several common aggregates for each column and returns the result. This is good function when you are performing exploratory data analysis (EDA)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mq0AkCMfoeh8"
      },
      "outputs": [],
      "source": [
        "df5 = pd.DataFrame({'A': rng.rand(10),\n",
        "                   'B': rng.rand(10),\n",
        "                   'C': rng.rand(10),\n",
        "                   'D': rng.rand(10)})\n",
        "df5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9Lw4iwtoeh8"
      },
      "outputs": [],
      "source": [
        "df5.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kj8lRwH0oeh8"
      },
      "source": [
        "Here is a listing of aggregates, and all of these operate on both dataframes and series objects. It would be good for you to remember these, and what each of them does.\n",
        "\n",
        "The following table summarizes some other built-in Pandas aggregations:\n",
        "\n",
        "| Aggregation              | Description                     |\n",
        "|--------------------------|---------------------------------|\n",
        "| ``count()``              | Total number of items           |\n",
        "| ``first()``, ``last()``  | First and last item             |\n",
        "| ``mean()``, ``median()`` | Mean and median                 |\n",
        "| ``min()``, ``max()``     | Minimum and maximum             |\n",
        "| ``std()``, ``var()``     | Standard deviation and variance |\n",
        "| ``mad()``                | Mean absolute deviation         |\n",
        "| ``prod()``               | Product of all items            |\n",
        "| ``sum()``                | Sum of all items                |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7K5M5iXfoeh8"
      },
      "source": [
        "### Groupby function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sIfVyU3oeh9"
      },
      "source": [
        "The pandas groupby() function allows you to perform aggregations on groups of your data. The function is typically used to aggregate conditionally on some row label or index. The function is (again) similar in usage to the SQL command 'group by'.\n",
        "\n",
        "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html\n",
        "\n",
        "The syntax for the groupby function is fairly straightforward, as most usages simply use the 'by' parameter to designate which column values the data will be grouped on. The function takes the values within the designated column(s) and performs the grouping (and subsequent aggregation).\n",
        "\n",
        "Under the covers, you can understand the groupby operation as on of split-apply-combine, as Hadley Wickham notes:\n",
        "\n",
        "1. Split the data into the groups, depending on the specified key value,\n",
        "\n",
        "2. Apply the aggregation function to each group,\n",
        "\n",
        "3. Combine the groups back together into a single dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT-ydMCyoeh9"
      },
      "source": [
        "![split-apply-combine.png](https://raw.githubusercontent.com/gt-cse-6040/skills_oh_week_07/main/split-apply-combine.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0atb65iKoeh9"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({'key': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
        "                   'data': range(6)}, columns=['key', 'data'])\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVLGN3rvoeh9"
      },
      "outputs": [],
      "source": [
        "display(df.groupby('key').sum())\n",
        "display(df.groupby('key').mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c65B4Ypoeh9"
      },
      "source": [
        "**VanderPlas has an excellent introduction to groupby in Chapter 3 of his book, available at the below links:**\n",
        "\n",
        "https://jakevdp.github.io/PythonDataScienceHandbook/03.08-aggregation-and-grouping.html\n",
        "\n",
        "https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.08-Aggregation-and-Grouping.ipynb\n",
        "\n",
        "We only touched on the most basic topics, and VanderPlas goes into great detail through the remainder of this notebook. We encourage you to use this supplemental material in your studies to learn about this function in greater detail."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uCNaKohoeh9"
      },
      "source": [
        "**This concludes our introduction to some important pandas functions.**\n",
        "\n",
        "**We encourage you to delve deeper into them, as you will be using all of these throughout this class and professionally in working with Python for Analytics.**\n",
        "\n",
        "**We also highly encourage you to work through NB7 Part1, the FEC Dataset notebook, as is does a full analysis of 'real life' data from the Federal Election Commission, including application of most of the above functions that we have covered here.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMrMVANfoeh9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "nteract": {
      "version": "0.11.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}